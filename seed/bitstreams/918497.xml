<article xsi:noNamespaceSchemaLocation="http://jats.nlm.nih.gov/publishing/1.1d1/xsd/JATS-journalpublishing1-mathml3.xsd" dtd-version="1.1d1" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="publisher-id">MPE</journal-id><journal-title-group><journal-title>Mathematical Problems in Engineering</journal-title></journal-title-group><issn pub-type="epub">1563-5147</issn><issn pub-type="ppub">1024-123X</issn><publisher><publisher-name>Hindawi Publishing Corporation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="other">918497</article-id><article-id pub-id-type="doi">10.1155/2012/918497</article-id><article-id pub-id-type="publisher-id">918497</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Parallel Motion Simulation of Large-Scale Real-Time Crowd in a Hierarchical Environmental Model</article-title></title-group><contrib-group><contrib contrib-type="author" id="U57606087" corresp="yes"><name><surname>Wang</surname><given-names>Xin</given-names></name><xref ref-type="aff" rid="I1"><sup>1</sup></xref></contrib><contrib contrib-type="author" id="U76781436"><name><surname>Zhang</surname><given-names>Jianhua</given-names></name><xref ref-type="aff" rid="I2"><sup>2</sup></xref></contrib><contrib contrib-type="author" id="U37549380"><name><surname>Scalia</surname><given-names>Massimo</given-names></name><xref ref-type="aff" rid="I3"><sup>3</sup></xref></contrib><contrib contrib-type="Academic Editor" id="U56957618"><name><surname>Cattani</surname><given-names>Carlo</given-names></name></contrib></contrib-group><aff id="I1"><sup>1</sup><addr-line>College of Computer Science and Technology</addr-line><addr-line>Zhejiang University of Technology</addr-line><addr-line>Hangzhou 310023</addr-line><country>China</country><ext-link ext-link-type="domain-name">zust.edu.cn</ext-link></aff><aff id="I2"><sup>2</sup><addr-line>TAMS Group, Department of Informatics</addr-line><addr-line>University of Hamburg</addr-line><addr-line>Vogt-Koelln-Stra&#xdf;e 30, 22527 Hamburg</addr-line><country>Germany</country><ext-link ext-link-type="domain-name">uni-hamburg.de</ext-link></aff><aff id="I3"><sup>3</sup><addr-line>Department of Mathematics</addr-line><addr-line>Sapienza University of Rome </addr-line><addr-line>Piazzale Aldo Moro 2, 00185 Rome</addr-line><country>Italy</country><ext-link ext-link-type="domain-name">uniroma1.it</ext-link></aff><pub-date pub-type="publication-year"><year>2012</year></pub-date><pub-date pub-type="archival-date"><day>6</day><month>6</month><year>2012</year></pub-date><volume>2012</volume><history><date date-type="received"><day>17</day><month>02</month><year>2012</year></date><date date-type="accepted"><day>28</day><month>03</month><year>2012</year></date></history><permissions><copyright-year>2012</copyright-year><copyright-holder>Copyright &#xa9; 2012 Xin Wang et al.</copyright-holder><license license-type="open-access"><license-p>This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p>This paper presents a parallel real-time crowd simulation method based on a hierarchical environmental model. A dynamical model of the complex environment should be constructed to simulate the state transition and propagation of individual motions. By modeling of a virtual environment where virtual crowds reside, we employ different parallel methods on a topological layer, a path layer and a perceptual layer. We propose a parallel motion path matching method based on the path layer and a parallel crowd simulation method based on the perceptual layer. The large-scale real-time crowd simulation becomes possible with these methods. Numerical experiments are carried out to demonstrate the methods and results.</p></abstract><counts><ref-count count="21" /><page-count count="15" /></counts></article-meta></front><body><sec sec-type="section" id="sec1"><title>1. Introduction</title><p>Real-time crowd simulation is one of the important research directions [<xref ref-type="bibr" rid="B1">1</xref>, <xref ref-type="bibr" rid="B2">2</xref>] in computer games, movies, and virtual reality. In the last decade, Shao et al. [<xref ref-type="bibr" rid="B3">3</xref>] proposed a multilevel model for the virtual crowd simulation in the face of visual effects, perception, routing, interactive and other issues directly and efficient support. Virtual environment modeling consists of two parts, that is, geometric environment modeling and nongeometric environment modeling [<xref ref-type="bibr" rid="B4">4</xref>]. Geometric environment model corresponds to the geometric layer of the hierarchical environmental model, and nongeometric environment model corresponds to the topology layer, the path layer, and the perception layer. There have existed some parallel methods [<xref ref-type="bibr" rid="B5">5</xref>], which can fast compute a scene path map based on the topology layer. However, they lacked parallel methods to accelerate real-time crowd simulation based on the path layer and the perception layer.</p><p>Given a motion path, matching human movements with it is a common problem in the field of character animation. Usually artist manually tuned the motion data. However, when lots of human movements need to be matched with lots of paths, only using manual method will be impractical and cannot meet the real-time requirements. Based on our analysis, we find that a parallel matching algorithm is suitable for motion path matching. Because motion matching between paths is independent of each other, the path segments among every two points within the calculation of the discrete sampling are independent. Based on the above investigations, this paper employs a parallel motion path matching algorithm based on the path layer.</p><p>Researchers often use the agent-based simulation model in crowd simulation. We found that single agent status updates only need to consider it within a limited range state of the world. Based on this observation, we designed a parallel crowd simulation method, employing a parallel update strategy and dividing the scene into bins (each bin is a square area; agents are distributed among all bins); we then determined the scope of each agent. For the nonadjacent bins, agents can employ parallel update strategy, which is divided into four batches of parallel updates. Experimental results show that this strategy can greatly increase update efficiency.</p><p>In the real world, each person makes appropriate movement decisions according to the state of the environment around him [<xref ref-type="bibr" rid="B6">6</xref>, <xref ref-type="bibr" rid="B7">7</xref>]. For example, when a car approaches, people will maintain their status or change their walking direction according to the car&#x2019;s driving direction, speed, and distance. The agent model proposed by Reynolds [<xref ref-type="bibr" rid="B8">8</xref>] can simulate these situations. The current research employed a similar but relatively simple agent model. Our agent is controlled by three forces: [<xref ref-type="bibr" rid="B9">9</xref>] avoiding the force of obstacles; avoiding collision with other agent forces; following path force [<xref ref-type="bibr" rid="B10">10</xref>, <xref ref-type="bibr" rid="B11">11</xref>]. The three forces are in order of decreasing priority.</p><p>This paper presents parallel real-time crowd simulation algorithms based on a hierarchy environmental model and fully taps the multilevel environmental model in the parallelism, making the simulation of large-scale real-time crowds possible.</p></sec><sec sec-type="section" id="sec2"><title>2. Related Work</title><p>Given a motion path, matching human movements with it is a common problem in the field of character animation. In the game industry, a relatively simple and efficient way is to loop the motion clip while the character moves along a motion path. This method makes the movements of characters appear mechanical, monotonous, and unrealistic in terms of imitating body movements. To achieve realistic effects, some scholars have proposed complex motion synthesis methods [<xref ref-type="bibr" rid="B12">12</xref>&#x2013;<xref ref-type="bibr" rid="B14">14</xref>]. The general approach first uses motion data, which are captured to construct a graph-like data structure. In searching this data structure for the right movement sequences to match input path, these sequences meet specific constraints that stitch up human posture, finally forming the results. When matching motion data with motion path, there exist some difficulties [<xref ref-type="bibr" rid="B15">15</xref>] as follows: (1) in the construction of the motion graph, if the graph is large and complex, determining what motion can be synthesized from the graph is difficult, and the range of new movements is unknown [<xref ref-type="bibr" rid="B16">16</xref>]; (2) the structure of the motion graph is complex, which takes a lot of time to search on the graph each time; hence, this structure cannot improve system performance [<xref ref-type="bibr" rid="B17">17</xref>]; (3) for the presence of path constraints, there are some low-level connection relationships in the motion graph, so there will be some unnecessary local shaking when synthesizing motion [<xref ref-type="bibr" rid="B12">12</xref>]; (4) some constraints need to be considered (e.g., obstacles); however, such methods are difficult to estimate.</p><p>Lau and Kuffner [<xref ref-type="bibr" rid="B18">18</xref>] described a similar method for this paper. The method organizes motion data into a finite state machine (FSM); each state represents a high-level semantical movement, such as walking and running. If two states can be connected together, there will be one connection in the state machine. Motion state machine is used to find the character&#x2019;s motion data when synthesizing motion, which can overcome the difficulties mentioned above. For multiple paths, this paper divided long path into short path segments. The length of these short path segments is almost equal to the motion segments in a motion state machine. Thus, when performing matching work, the efficiency of matching can be improved. This paper also used parallel computing strategy to greatly reduce the time required for each planning step. In addition, when using motion state machine to match, a benefit arises; that is, while the current matching segment crosses paths with other motion path segments, a collision situation is possible; if such a situation happens, there will be no displacement motion data (idle) for the role to effectively avoid the collision. On the other hand, when more human movements are required to match more paths, solely using such methods cannot meet the real-time requirements.</p><p>The agent-based crowd simulation model is accorded the characteristics of crowd movement in the real world and has a very flexible control strategy (e.g., controlling each parameter of each agent). Therefore, agent-based crowd simulation model is widely used. However, for large-scale real-time crowd simulation, each agent needs to update its own status according to its surrounding environment, and each agent is a dynamic obstacle to other agents. Computing cost increases rapidly as the number of agent increases [<xref ref-type="bibr" rid="B19">19</xref>] in the face of time complexity <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1"><mml:mi>O</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:math></inline-formula>. Thus, when n is large, the time required for each frame will significantly increase, making the real-time status update of each agent impossible. Hence, we need to find a new method to do large-scale crowd simulation.</p></sec><sec sec-type="section" id="sec3"><title>3. Overview</title><p>The system consists of two parts: (1) hierarchy environment model and (2) multiple parallel algorithms based on the hierarchy (see Figure <xref ref-type="fig" rid="fig1">1</xref>).</p><fig id="fig1"><label>Figure 1</label><caption><p>System overview.</p></caption><graphic xlink:href="918497.fig.001" /></fig><p>The hierarchy environmental model [<xref ref-type="bibr" rid="B20">20</xref>], as shown in Figure <xref ref-type="fig" rid="fig1">1</xref> (right panel), consists of two parts: geometric and non-geometric environment model. The non-geometric environment model includes the topology layer, path layer, and perception layer.</p><p>Based on the multi-level environment, the topology layer, path layer, and perception layer employ different parallel algorithms to speed up real-time crowd simulation, respectively, as shown in Figure <xref ref-type="fig" rid="fig1">1</xref> (left panel). We employed the existing Voronoi diagram algorithm [<xref ref-type="bibr" rid="B4">4</xref>] based on topology layer to segment the scene quickly and get the path layer map. We also used parallel motion path matching based on path layer to quickly match human motion for path, as well as parallel real-time crowd simulation based on perception layer to fully tap the crowd behavior in parallelism.</p></sec><sec sec-type="section" id="sec4"><title>4. Parallel Motion Path Matching Based on Path Layer</title><p>This section explains parallel motion path matching based on path layer. The section contains three parts: (1) motion state machine, (2) motion path parameterization, and (3) extraction of motion segments.</p><sec sec-type="subsection" id="sec4.1"><title>4.1. Motion State Machine</title><p>The main differences between the motion state machine proposed by Kovar et al. [<xref ref-type="bibr" rid="B12">12</xref>] and the motion state machine constructed in this paper are as follows: (1) trajectory arc length of the node of motion segments used by each state is fixed and equal in this paper&#x2019;s motion state machine; (2) the length of most of the motion segments in this paper is longer than that in Kovar et al. [<xref ref-type="bibr" rid="B12">12</xref>]. For example, there are 100 frame movements about walking used in this paper, but the length of the movements in Da Silva et al. [<xref ref-type="bibr" rid="B21">21</xref>] is only 25 frames; (3) the motion state machine in this paper employed group-based hierarchical status node, which can ensure that &#x201c;walk left&#x201d; and &#x201c;run left&#x201d; are on the same level, and all directional run and walk movements comprise a position move node on the up level. Three facts exist in the motion synthesis process, which lead to the above differences: (1) this paper used sectional matching; (2) the movement range of the motion path to be matched is large; (3) the connection relationships among states are more complex.</p><p>The motion state machine (MSM) used in this paper is shown in Figure <xref ref-type="fig" rid="fig2">2</xref>. The MSM has a total of 12 base states, which have their own names and include 36 motion segments (except start and end states). The motion segments&#x2019; arc length of &#x201c;Crawl,&#x201d; &#x201c;Squat move,&#x201d; and &#x201c;Stride over&#x201d; is indeterminate, because these motion segments are mainly used to deal with the path segments about obstacles. These are marked directly by users to explain which motion segments are used, so that the system does not need to match in the rear. The function of the &#x201c;Idle&#x201d; state&#x2019;s motion segments is to make the virtual characters wait, so that the system can avoid the collision between virtual characters. The states, which include &#x201c;run forward,&#x201d; &#x201c;run left,&#x201d; &#x201c;run right,&#x201d; &#x201c;walk forward,&#x201d; &#x201c;walk left,&#x201d; and &#x201c;walk right,&#x201d; describe the ways in which virtual characters can match according to the specific path situation. Furthermore, the motion path&#x2019;s arc length of motion segments is equal, which makes the matching of motion path segments easy.</p><fig id="fig2"><label>Figure 2</label><caption><p>Finite motion state machine.</p></caption><graphic xlink:href="918497.fig.002" /></fig><p>There are some directed edges among states in MSM. These directed edges express whether two motion segments can be connected. For example, there is a directed edge between &#x201c;run right&#x201d; and &#x201c;walk right,&#x201d; which means that the motion segments of &#x201c;run right&#x201d; can stitch with the motion segments of &#x201c;walk right.&#x201d; Similarly, the motion segments of &#x201c;walk left&#x201d; can stitch with the motion segments of &#x201c;run left.&#x201d; The motion machine in this paper adopts a group-based hierarchical status node. For example, &#x201c;walk forward&#x201d; and &#x201c;run forward&#x201d; constitute F, &#x201c;run left&#x201d; and &#x201c;walk left&#x201d; constitute L, and &#x201c;run right&#x201d; and &#x201c;walk right&#x201d; constitute R. Finally, L, F, and R constitute locomotion. The child states can inherit the father states&#x2019; connection. For example, the connection between F and R explains that &#x201c;walk forward&#x201d; and &#x201c;run right&#x201d; can connect with each other, and the connection between the &#x201c;crawl&#x201d; state and l locomotion can lead to the connection between &#x201c;crawl&#x201d; and &#x201c;run left.&#x201d;</p><p>This paper also prepares some transitional motion segments. These motion data are used to connect the transitional fragments among motion segments. There are eight frames. The transitional fragments exist at the beginning and the end of motion segments.</p></sec><sec sec-type="subsection" id="sec4.2"><title>4.2. Motion Path Parameterization</title><p>In this paper, there is a path planner responsible for generating a parameterized original movement path called &#x201c;<italic>T</italic>&#x201d; and decides the grid size of path planning pace. If the planning space is planed in a lattice structure, which is composed of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2"><mml:mi>m</mml:mi><mml:mi>&#x2a;</mml:mi><mml:mi>m</mml:mi></mml:math></inline-formula> square, the space between 2<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> point sequence is <italic>m</italic>, but in the specific application, the space of sample points cannot keep the same with the sample degree of the original path. For example, in this research, the human root node movement size between two frames is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> in the MSM. However, the motion clips in the MSM were prepared before motion synthesis and cannot be resampled. The system initially needs to use some fitting methods to parameterize the original path and then resamples the parametric path based on the desired sampling size. The resulting path can be used to match the crowd animation better in the following phase. In detail, our method constructs the cubic polynomial curve <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5"><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> continuous based on the original data point. If there is a curve formula called <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7"><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the system begins with a starting point <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and records those points <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x2026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, whose arc length spacing is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula> and corresponding parameters <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x2026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The characteristics of cubic polynomial spline curve with <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> continuous are simple and easy to control, and human motion path is generally not so smooth that curve with <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> continuous is enough to make the motion path smooth through fitting.</p><p>In addition, the algorithm needs the corresponding tangent vector of each sample point. The system can calculate <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14"><mml:mi>p</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> curve&#x2019;s tangent vector in <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x2026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> through parameters <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16"><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>&#x2009;&#x2009;</mml:mi><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x2026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. Then, it can represent the motion path after normalizing with the coordinates of parameters point and tangent vector, called <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula id="EEq4.1"><label>(4.1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mo>&#x020d7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>The arc length in our motion segments in the MSM is almost equal. The arc length of motion state <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> is represented by <italic>li</italic>. If <italic>li</italic> is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> times as long as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, motion path <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> used in experiment general is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M23"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> times longer than <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>. Hence, it can cut up the whole path into many small segments whose length is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M25"><mml:mi>n</mml:mi><mml:mi>&#x2a;</mml:mi><mml:mi>s</mml:mi></mml:math></inline-formula>. For example, suppose there are <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26"><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> points from <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M27"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The algorithm can find motion segments called <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M29"><mml:mtext>motio</mml:mtext><mml:msub><mml:mrow><mml:mtext>n</mml:mtext></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the MSM, which is similar to the path curve shape. If there are some obstacles in the path, direct matching cannot be performed. The path is marked by specific segments of motion data through interaction. Then, it can stitch directly in the matching phrase.</p><p>There are some crossings of motion paths and obstacles in <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M30"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, matching directly to <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M31"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is not enough. An artificial mark on this cross-path, such as &#x201c;crawl&#x201d; state, is needed. In the matching, when meeting this path, motion data are directly found under the &#x201c;crawl&#x201d; state and are associated with motion path <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M32"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula id="EEq4.2"><label>(4.2)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M33"><mml:mtable class="split"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x020d7;</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>motion</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext>motion</mml:mtext></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>;</mml:mo><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mi>n</mml:mi><mml:mo>;</mml:mo><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mn>0</mml:mn><mml:mo>&#x0003c;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>j</mml:mi><mml:mo>;</mml:mo><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>The path segments composed of continuous t points from <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M34"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> have been associated with motion data called <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M35"><mml:mrow><mml:msub><mml:mrow><mml:mtext>motion</mml:mtext></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>; <italic>r</italic> means that this mark is the <italic>r</italic>-section in all <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M36"><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> marks. Figure <xref ref-type="fig" rid="fig3">3</xref> shows the normalized conversion process from curve <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M37"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> to curve <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M38"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p><fig id="fig3"><label>Figure 3</label><caption><p>Normalized conversion process from curve <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M39"><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula> to curve <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M40"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p></caption><graphic xlink:href="918497.fig.003" /></fig></sec><sec sec-type="subsection" id="sec4.3"><title>4.3. Extraction of Motion Segments</title><p><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M41"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> changes into <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M42"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> through parametric resampling and marking the specific segment. Setting the path consists of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M43"><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> points, and total arc length is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M44"><mml:mi>n</mml:mi><mml:mi>&#x2a;</mml:mi><mml:mi>s</mml:mi></mml:math></inline-formula>. The basic motion segment of the root node&#x2019;s path curves arc length is certain, set as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M45"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>, such as &#x201c;walk&#x201d; and &#x201c;run.&#x201d; <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M46"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula> is also integer times as <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M47"><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, set as <italic>k</italic>. Thus, <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M48"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> needs to be cut into path segments, whose arc length is <italic>d</italic>. The set of this path segments is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M49"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula>. Consider
								<disp-formula id="EEq4.3"><label>(4.3)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M50"><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>size</mml:mtext></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>
							where<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M51"><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> means the <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M52"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>th motion path segment. <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M53"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mtext>size</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> means the total number of segments after cutting:<disp-formula id="EEq4.4"><label>(4.4)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M54"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mtext>starting</mml:mtext><mml:mi>&#x2009;&#x2009;</mml:mi><mml:mtext>coordinates</mml:mtext></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Figure <xref ref-type="fig" rid="fig4">4</xref> shows the <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M55"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> segmentation process.</p><fig id="fig4"><label>Figure 4</label><caption><p>Schematic diagram of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M56"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> segmentation.</p></caption><graphic xlink:href="918497.fig.004" /></fig><p>The next work that needs to be done is using the distance formula <italic>D </italic>to find proper motion segment motion<italic><sub>k</sub></italic> for each <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M57"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>This paper designs a one-dimensional Grid (motionNum, 1) for single curve. motionNum means the number of motion segments in the database, and one Grid has motionNum blocks. Each block is responsible for calculating its representative motion segments. For example, block0 is only responsible for calculating the matching degree between the current line and the 0th motion segment. Each block is one-dimensional. For example, in block (PointNum, 1), PointNum means the number of discrete points currently calculating the curve segment matching. Each thread in the block means the distance between a discrete point in the curve and the corresponding point in the motion segment. For example, thread0 is responsible for calculating the distance of 0th discrete point. The formula is<disp-formula id="EEq4.5"><label>(4.5)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M58"><mml:msub><mml:mrow><mml:mtext>distance</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:msub><mml:mrow><mml:mtext>CurvePoint</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mtext>MotionPoint</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:msqrt><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>Each thread only needs to calculate its own data, and it does not need to interact with other threads. After the final computation, thread0 accumulates matching value, calculating by each thread, and acquires the total matching value between the curve and the motion segment. The computation formula is<disp-formula id="EEq4.6"><label>(4.6)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M59"><mml:mtext>MatchDegree</mml:mtext><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mtext>distance</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>After calculating the matching value with all motion segments, the minimum matching value is obtained through comparison. The final result is<disp-formula id="EEq4.7"><label>(4.7)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M60"><mml:mtext>Motion</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mtext>MatchDegree</mml:mtext></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi><mml:mo>&#x2061;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mtext>MatchDegree</mml:mtext></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>The matching effect of single curve is shown in Figure <xref ref-type="fig" rid="fig6">6</xref>, and its internal thread organization way is depicted in Figure <xref ref-type="fig" rid="fig5">5</xref>. Before calculating the distance between a discrete point in curve and the corresponding point in motion segment, every point in a motion segment needs to do a rotating translation operation. This step is necessary because motion segment only converts to a curve&#x2019;s local coordinate. The matching value can be obtained accurately. Now, the system selects thread0 to calculate rotation and offset. Meanwhile, the other threads wait for the calculating result of thread. Then, they share the calculating result of thread0.</p><fig id="fig5"><label>Figure 5</label><caption><p>Schematic diagram of Grid (<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M61"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula>,1). </p></caption><graphic xlink:href="918497.fig.005" /></fig><fig id="fig6"><label>Figure 6</label><caption><p>Matching effect of single curve.</p></caption><graphic xlink:href="918497.fig.006" /></fig><p>We need to design a two-dimensional Grid (motionNum, CurveNum) to extend to multiple curves, as shown in Figure <xref ref-type="fig" rid="fig7">7</xref>. motionNum means the number of motion segments. CurveNum means the number of curves. Others are similar to the single curve. The matching effect of multiple curves is illustrated in Figure <xref ref-type="fig" rid="fig8">8</xref>.</p><fig id="fig7"><label>Figure 7</label><caption><p>Schematic diagram of Grid (<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M62"><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula>,<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M63"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>). </p></caption><graphic xlink:href="918497.fig.007" /></fig><fig id="fig8"><label>Figure 8</label><caption><p>Matching effect of multiple curves.</p></caption><graphic xlink:href="918497.fig.008" /></fig><p>This method can achieve better expansibility. If there are more motion segments that need to match, then the dimension of Grid only increases.</p></sec></sec><sec sec-type="section" id="sec5"><title>5. Parallel Real-Time Crowd Simulation Based on Perception Layer</title><p>This section explains how to parallel real-time crowd simulation based on perception layer. This section contains three parts: (1) scene segmentation; (2) nearest neighbor query; (3) parallel real-time crowd simulation. </p><sec sec-type="subsection" id="sec5.1"><title>5.1. Scene Segmentation</title><p>In agent-based crowd simulation, each agent has its own perceived range. In each update, each agent must query the scope of its perception to obtain the range of obstacles or information of other agents. Then, based on the information to calculate the forces acting on the agents, their speed and direction can be adjusted, and the location can be updated. Neighbor queries generally employ serial query that is executed when the current agent is updated. Then, the next agent begins to update. In this algorithm, using parallel neighbor query, the main query is the bin, rather than each agent. Through these neighbor queries, the bin can be obtained, in which agents need to consider all the potential neighbor agents. Before the implementation of parallel neighbors&#x2019; query, the entire scene needs to be evenly segmented to get all the information about the bin.</p><p>The segmentation needs to be completed in the initialization process. The size of the entire scene is <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M64"><mml:mn>1200</mml:mn><mml:mo>&#xd7;</mml:mo><mml:mn>1200</mml:mn></mml:math></inline-formula>; setting the side length of each bin is 4 for the square, so that the whole scene is to be divided into <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M65"><mml:mn>300</mml:mn><mml:mo>&#xd7;</mml:mo><mml:mn>300</mml:mn></mml:math></inline-formula>&#x2009;bins. The square side length is 4, because the sensing range of agent sets a circular area that is a query radius of 4. The formula is as follows:<disp-formula id="EEq5.1"><label>(5.1)</label><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M66"><mml:mtext>queryRadius</mml:mtext><mml:mo>=</mml:mo><mml:mtext>predTime</mml:mtext><mml:mi>*</mml:mi><mml:mtext>maxVelocity</mml:mtext><mml:mi>*</mml:mi><mml:mn>2</mml:mn><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>The predTime is the forward predictive time, set as 1&#x2009;s. <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M67"><mml:mrow><mml:mtext>maxVelocity</mml:mtext></mml:mrow></mml:math></inline-formula> is the agent&#x2019;s maximum move speed, set as 2&#x2009;m/s. In the query process, only 8 bins need to be considered, which are around the center bin.</p><p>As shown in Figure <xref ref-type="fig" rid="fig9">9</xref>, the scene is evenly divided into a number of bins, the scene of the agents located in each bin. There are multiple agents in a bin; however, a bin can also have no agent.</p><fig id="fig9"><label>Figure 9</label><caption><p>Scene segmentation and agent distribution (circle represents the agent).</p></caption><graphic xlink:href="918497.fig.009" /></fig></sec><sec sec-type="subsection" id="sec5.2"><title>5.2. Nearest Neighbor Query</title><p>After scene segmentation and statistical distribution among the agents in each bin, the nearest neighbor query is employed. In the scene segmentation step, each Agent&#x2019;s observation range is a circular area of radius 4, and the bin side is also 4. Thus, the algorithm only needs to check the bin and approximately 8 bins. Figure <xref ref-type="fig" rid="fig10">10</xref> shows that the number of green bins is 49 and the observation range is the dashed circle. Hence, the bin numbers that need to be checked are 37, 38, 39, 48, 49, 50, 59, 60, and 61. As the neighbor queries between the bins only read data with no write operation, this paper chooses the parallel query; the query results are saved in the corresponding data structures.</p><fig id="fig10"><label>Figure 10</label><caption><p>Observation range of bin (dashed circle).</p></caption><graphic xlink:href="918497.fig.0010" /></fig></sec><sec sec-type="subsection" id="sec5.3"><title>5.3. Parallel Real-Time Crowd Simulation</title><p>After completing the nearest neighbor querying, crowd velocity, and position updating, the next Agent begins to update. At the step of parallel nearest neighbor query, the algorithm has queried all the neighbors of the bin. However, as the Agents of the adjacent bin would interact, this step of the update operation cannot be completely parallel. For example, for bin 48 and bin 49, if the two parallels update, there would be a read/write conflict. The reason is that when the Agents of bin 48 are updating, the Agents of bin 49 should be considered; hence, the reading data may be outdated Agent data of bin 49, and vice versa. Therefore, this paper chooses partial parallel update strategy; steps are described below in detail.</p><p>Referring to the behavior rules of pedestrians in the real world and traditional Agent model, the Agent model used in this paper is acted upon by three kinds of forces, namely, (1) avoid the force of obstacles; (2) avoid collision with other Agent forces; (3) follow the path of force. Figure <xref ref-type="fig" rid="fig11">11</xref> illustrates each kind of force.</p><fig id="fig11"><label>Figure 11</label><caption><p>Schematic diagram of agent&#x2019;s three kinds of forces.</p></caption><graphic xlink:href="918497.fig.0011" /></fig><p>Three kinds of forces decline in priority order. Avoiding the behavior of obstacles is the highest priority; that is, when Agent <italic>k</italic> detects it will crash into obstacle <italic>d</italic>, it also may have collided with Agent <italic>g</italic>, and then it would only consider avoiding obstacle <italic>d</italic>. Considering that the obstacle is stationary, if the Agent does not adjust its speed, it will be hit and move. Even if Agent <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M68"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula> does not make an adjustment, Agent <italic>g</italic> itself can adjust the speed for Agent <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M69"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>. Avoiding force is calculated as follows. Agent forward predictive distance with the observed radius builds up a rectangular area; in the region of collision, we can find the nearest obstacle. As shown in Figure <xref ref-type="fig" rid="fig11">11</xref> for obstacle <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M70"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:math></inline-formula>, avoiding force (Force <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M71"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>) for the current Agent is pull force and the obstacle repulsive force direction. Another situation is when Agent <italic>j</italic> moves to prediction <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M72"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>&#x2019; position, and Agent <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M73"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> will reach position <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M74"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> at the same time. When the distance between position <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M75"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> and position <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M76"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> is less than the distance between the center of the radius of their observations, a collision will be assumed; thus, they will not be influenced by the force of path-following, but by the Agent force between the impact of avoidance, the avoidance of force as a lateral tension (Force <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M77"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>), to deviate the current running direction. In Figure <xref ref-type="fig" rid="fig11">11</xref>, there is a lane in the path (dotted line parallel with the path and the distance between the path); the current updated Agent will forecast forward for some distance to predict the location of <italic>P</italic> projected onto the path <italic>P</italic>&#x2019; point. If the distance between <italic>P</italic>&#x2019; and <italic>P</italic> is greater than the lane, then the Agent&#x2019;s travel direction deviates from the path; otherwise, there is no deviation. As shown in Figure <xref ref-type="fig" rid="fig11">11</xref>, Agent h would be acted upon by the force of path following (Force <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M78"><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>), for the projection point <italic>P</italic>&#x2019; of the direction of the Agent center of the connection to slowly move closer to the path direction.</p><p>This paper makes parallel updates on the Agent rates four times. As shown in Figure <xref ref-type="fig" rid="fig10">10</xref>, the bin has a total of four colors. Each time parallel updates the bin that has the same color. When all colors have been updated, a general update is completed. Agents within the same bin have an impact on each other, but they cannot be updated in parallel; hence, the serial update can only be used. In the implementation process, each block represents a bin, following the Agent model above; meanwhile, according to the priority of various types of forces, the research also carries out the appropriate adjustments.</p></sec></sec><sec sec-type="section" id="sec6"><title>6. Experimental Results</title><p>In general, the experiment platform uses a computer of 4 core (Q9950 CPU at 2.83&#x2009;GHz and 4&#x2009;GB of RAM), equipped with a NVIDIA GTX 280 graphics card, which has 30 multiprocessors. Each multiprocessor has 8 cores; the total number of cores is 240. The CPU-based algorithm achieves serial algorithms, and the GPU-based algorithm achieves the proposed parallel algorithms in this paper.</p><p>Figure <xref ref-type="fig" rid="fig12">12</xref> clearly shows that in the path matching based on path layer, with the increase in the number of curves that are required for matching, the CPU&#x2019;s execution time increases significantly, whereas the GPU&#x2019;s execution time barely increases.</p><fig id="fig12"><label>Figure 12</label><caption><p>Comparison between CPU-based and GPU-based algorithms.</p></caption><graphic xlink:href="918497.fig.0012" /></fig><p>Table <xref ref-type="table" rid="tab1">1</xref> lists the matching time based on the path matching on the path layer with the CPU matching algorithm and GPU matching algorithm under some curve lines. The data in the table indicate that GPU parallel algorithm would increase by about 20 times than the CPU algorithm in execution speed.</p><table-wrap id="tab1"><label>Table 1</label><caption><p>Comparison between CPU and GPU execution time.</p></caption><table><thead><tr><th align="left" /><th align="center"> 10</th><th align="center"> 100</th><th align="center"> 200</th><th align="center"> 500</th><th align="center"> 1000</th></tr></thead><tbody><tr><td align="left">CPU execution time (ms)</td><td align="center"> 1214.9124</td><td align="center"> 11999.31</td><td align="center"> 25312.8457</td><td align="center"> 56183.2070</td><td align="center"> 112101.531</td></tr><tr><td align="left">GPU execution time (ms)</td><td align="center"> 70.2647</td><td align="center"> 549.388</td><td align="center"> 1049.8966</td><td align="center"> 2572.0297</td><td align="center"> 5188.6655</td></tr></tbody></table></table-wrap><p>Figure <xref ref-type="fig" rid="fig13">13</xref> shows the frame rate comparison between GPU parallel algorithm and CPU serial algorithm in real-time crowd simulation based on the perceived layer.</p><fig id="fig13"><label>Figure 13</label><caption><p>Performance comparison between CPU and GPU in crowd simulation.</p></caption><graphic xlink:href="918497.fig.0013" /></fig><p>As can be seen from Figure <xref ref-type="fig" rid="fig13">13</xref> GPU-based parallel computing speed is significantly higher than the CPU-based parallel computing speed in crowd simulation. With the increase in the number of Agents, CPU-based FPS drops very quickly. When the number reaches more than 5,000, real-time simulation results are not achieved. Although the GPU program number is above 10000 of the Agent, FPS can reach 24 or more, fully meeting the real-time requirement. When the number is 1000, the FPS of the GPU is 60.</p><p>In addition, as the curves indicate, the FPS of GPU-based algorithms is significantly higher than that of the CPU-based algorithms, but it still has not reached 10 or more times. The main reason is the speed of Agent updating; there are a lot of conditional executions, such as statements reducing the parallel computing efficiency of the GPU-based algorithm.</p></sec><sec sec-type="section" id="sec7"><title>7. Discussion</title><p>Through the proposed parallel algorithms in this paper, we achieve a completely parallel real-time crowd simulation based on a hierarchy environmental model, making topology layer, path layer, and perception layer have corresponding parallel algorithms to speed up the calculation.</p><p>This paper describes the detailed process with the path layer-based motion path matching, through the structure of motion state machine, setting up the transfer relationship among movement segments. Specifying the sequence of key points, this paper chooses cubic spine curve fitting to get a continuous path and then samples the sequence of points needed. We use the distance function to calculate the matching degree between the motion segment and the path, then accumulate the value of discrete points, and get the total matching degree of the corresponding segment. Moreover, this paper explains the use of parallel computing algorithms to accelerate and verify the algorithm through data analysis.</p><p>This paper introduces parallel computing algorithm based on the perception layer to achieve real-time simulation of large crowds. Using scene segmentation evenly, according to his own location, each Agent is assigned to the appropriate bin where the original calculations must be serialized into parallel computing. Each bin is a separate update unit.</p><p>Experimental results suggest that the proposed method in this paper is consistent with the serial method in effect, but efficiency has been greatly improved. Given that the Agent model used in this paper is relatively simple, the focus of future work is how to use more complex models to achieve a more realistic real-time crowd simulation, reduce the occurrence times of logic-based computing in the parallel algorithm framework, and further improve the algorithm&#x2019;s parallelism.</p></sec></body><back><ack><title>Acknowledgments</title><p>This work was supported by Natural Science Foundation of Zhejiang Province (Y1110882, Y1110688, R1110679), Department of Education of Zhejiang Province (Y200907765, Y201122434), and Doctoral Fund of Ministry of Education of China (20113317110001).</p></ack><ref-list><ref id="B1" content-type="article"><label>1</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farenc</surname><given-names>N.</given-names></name><name><surname>Musse</surname><given-names>S. R.</given-names></name><name><surname>Schweiss</surname><given-names>E.</given-names></name><name><surname>Kallmann</surname><given-names>M.</given-names></name><name><surname>Aune</surname><given-names>O.</given-names></name><name><surname>Boulic</surname><given-names>R.</given-names></name><name><surname>Thalmann</surname><given-names>D.</given-names></name></person-group><article-title>A paradigm for controlling virtual humans in urban environment simulations</article-title><source><italic>Applied Artificial Intelligence</italic></source><year>2000</year><volume>14</volume><issue>1</issue><fpage>69</fpage><lpage>91</lpage><pub-id pub-id-type="other">2-s2.0-0033993130</pub-id></nlm-citation></ref><ref id="B2" content-type="inproceedings"><label>2</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tecchia</surname><given-names>F.</given-names></name><name><surname>Loscos</surname><given-names>C.</given-names></name><name><surname>Conroy</surname><given-names>R.</given-names></name><etal /></person-group><article-title>Agent Behavior Simulator (ABS): a platform for urban behavior development</article-title><conf-name>Proceedings of Games Technology Conference</conf-name><conf-date>2001</conf-date></nlm-citation></ref><ref id="B3" content-type="inproceedings"><label>3</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>M.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Hou</surname><given-names>Y.</given-names></name></person-group><article-title>Crowd evacuation simulation based on a hierarchy environmental model</article-title><conf-name>Proceedings of the  IEEE 10th International Conference on Computer-Aided Industrial Design and Conceptual Design: E-Business, Creative Design, Manufacturing (CAID &#x26; CD '09)</conf-name><conf-date>November 2009</conf-date><fpage>1075</fpage><lpage>1078</lpage><pub-id pub-id-type="other">2-s2.0-77949644950</pub-id><pub-id pub-id-type="doi">10.1109/CAIDCD.2009.5375275</pub-id></nlm-citation></ref><ref id="B4" content-type="article"><label>4</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Cattani</surname><given-names>C.</given-names></name></person-group><article-title>Key issues in modeling of complex 3D structures from video sequences</article-title><source><italic>Mathematical Problems in Engineering</italic></source><year>2012</year><volume>2012</volume><lpage>17</lpage><pub-id pub-id-type="publisher-id">856523</pub-id><pub-id pub-id-type="doi">10.1155/2012/856523</pub-id></nlm-citation></ref><ref id="B5" content-type="article"><label>5</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denny</surname><given-names>M.</given-names></name></person-group><article-title>Solving geometric optimization problems using graphics hardware</article-title><source><italic>Computer Graphics Forum</italic></source><year>2003</year><volume>22</volume><issue>3</issue><fpage>441</fpage><lpage>451</lpage><pub-id pub-id-type="other">2-s2.0-0141504423</pub-id><pub-id pub-id-type="doi">10.1111/1467-8659.00692</pub-id></nlm-citation></ref><ref id="B6" content-type="article"><label>6</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name></person-group><article-title>Acceleration strategies in generalized belief propagation</article-title><source><italic>IEEE Transactions on Industrial Informatics</italic></source><year>2012</year><volume>8</volume><issue>1</issue><fpage>41</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1109/TII.2011.2172449</pub-id></nlm-citation></ref><ref id="B7" content-type="article"><label>7</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S. Y.</given-names></name><name><surname>Tong</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Zhang</surname><given-names>B.</given-names></name></person-group><article-title>Improved generalized belief propagation for vision processing</article-title><source><italic>Mathematical Problems in Engineering</italic></source><year>2011</year><volume>2011</volume><lpage>12</lpage><pub-id pub-id-type="publisher-id">416963</pub-id><pub-id pub-id-type="doi">10.1155/2011/416963</pub-id></nlm-citation></ref><ref id="B8" content-type="inproceedings"><label>8</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>C. W.</given-names></name></person-group><person-group person-group-type="editor"><name><surname>Stone</surname><given-names>M. C.</given-names></name></person-group><article-title>A distributed behavioral model</article-title><conf-name>Proceedings of the ACM Computer Graphics (SIGGRAPH &#x2019;87)</conf-name><conf-date>1987</conf-date><fpage>25</fpage><lpage>34</lpage><pub-id pub-id-type="other">2-s2.0-0023379184</pub-id></nlm-citation></ref><ref id="B9" content-type="book"><label>9</label><nlm-citation publication-type="book"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>C. W.</given-names></name></person-group><source><italic>Steering Behaviors for Autonomous Characters</italic></source><year>1999</year><publisher-loc>Boulevard Foster City, Calif, USA</publisher-loc><publisher-name>Sony Computer Entertainment America</publisher-name></nlm-citation></ref><ref id="B10" content-type="article"><label>10</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Zhao</surname><given-names>W.</given-names></name></person-group><article-title>Visiting power laws in cyber-physical networking systems</article-title><source><italic>Mathematical Problems in Engineering</italic></source><year>2012</year><volume>2012</volume><lpage>13</lpage><pub-id pub-id-type="publisher-id">302786</pub-id><pub-id pub-id-type="doi">10.1155/2012/302786</pub-id></nlm-citation></ref><ref id="B11" content-type="article"><label>11</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Zhao</surname><given-names>W.</given-names></name></person-group><article-title>Representation of a stochastic traffic bound</article-title><source><italic>IEEE Transactions on Parallel and Distributed Systems</italic></source><year>2010</year><volume>21</volume><issue>9</issue><fpage>1368</fpage><lpage>1372</lpage><pub-id pub-id-type="other">2-s2.0-77955227336</pub-id><pub-id pub-id-type="doi">10.1109/TPDS.2009.162</pub-id></nlm-citation></ref><ref id="B12" content-type="inproceedings"><label>12</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kovar</surname><given-names>L.</given-names></name><name><surname>Gleicher</surname><given-names>M.</given-names></name><name><surname>Pighin</surname><given-names>F.</given-names></name></person-group><article-title>Motion graphs</article-title><conf-name>Proceedings of the ACM Transactions on Graphics (ACM SIGGRAPH '02)</conf-name><conf-date>July 2002</conf-date><fpage>473</fpage><lpage>482</lpage><pub-id pub-id-type="other">2-s2.0-0036993198</pub-id></nlm-citation></ref><ref id="B13" content-type="inproceedings"><label>13</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Arikan</surname><given-names>O.</given-names></name><name><surname>Forsyth</surname><given-names>D. A.</given-names></name></person-group><article-title>Interactive motion generation from examples</article-title><conf-name>Proceedings of the ACM Transactions on Graphics (ACM SIGGRAPH '02)</conf-name><conf-date>July 2002</conf-date><fpage>483</fpage><lpage>490</lpage><pub-id pub-id-type="other">2-s2.0-0036992635</pub-id></nlm-citation></ref><ref id="B14" content-type="inproceedings"><label>14</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Chai</surname><given-names>J.</given-names></name><name><surname>Reitsma</surname><given-names>P. S. A.</given-names></name><name><surname>Hodgins</surname><given-names>J. K.</given-names></name><name><surname>Pollard</surname><given-names>N. S.</given-names></name></person-group><article-title>Interactive control of avatars animated with human motion data</article-title><conf-name>Proceedings of the ACM Transactions on Graphics (ACM SIGGRAPH '02)</conf-name><conf-date>July 2002</conf-date><fpage>491</fpage><lpage>500</lpage><pub-id pub-id-type="other">2-s2.0-0036992636</pub-id></nlm-citation></ref><ref id="B15" content-type="article"><label>15</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S. Y.</given-names></name><name><surname>Tong</surname><given-names>H.</given-names></name><name><surname>Cattani</surname><given-names>C.</given-names></name></person-group><article-title>Markov models for image labeling</article-title><source><italic>Mathematical Problems in Engineering</italic></source><year>2012</year><volume>2012</volume><lpage>18</lpage><pub-id pub-id-type="publisher-id">814356</pub-id><pub-id pub-id-type="doi">10.1155/2012/814356</pub-id></nlm-citation></ref><ref id="B16" content-type="inproceedings"><label>16</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Reitsma</surname><given-names>P. S. A.</given-names></name><name><surname>Pollard</surname><given-names>N. S.</given-names></name></person-group><article-title>Evaluating motion graphs for character navigation</article-title><conf-name>Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation</conf-name><conf-date>2004</conf-date><conf-loc>Grenoble, France</conf-loc><fpage>89</fpage><lpage>98</lpage></nlm-citation></ref><ref id="B17" content-type="article"><label>17</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Lee</surname><given-names>K. H.</given-names></name></person-group><article-title>Precomputing avatar behavior from human motion data</article-title><source><italic>Graphical Models</italic></source><year>2006</year><volume>68</volume><issue>2</issue><fpage>158</fpage><lpage>174</lpage><pub-id pub-id-type="other">2-s2.0-33644598606</pub-id><pub-id pub-id-type="doi">10.1016/j.gmod.2005.03.004</pub-id></nlm-citation></ref><ref id="B18" content-type="inproceedings"><label>18</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lau</surname><given-names>M.</given-names></name><name><surname>Kuffner</surname><given-names>J. J.</given-names></name></person-group><article-title>Behavior planning for character animation</article-title><conf-name>Proceedings of the 5th Eurographics Symposium on Computer Animation (ACM SIGGRAPH '05)</conf-name><conf-date>July 2005</conf-date><conf-loc>Los Angeles, Calif, USA</conf-loc><fpage>271</fpage><lpage>280</lpage><pub-id pub-id-type="other">2-s2.0-47249161706</pub-id><pub-id pub-id-type="doi">10.1145/1073368.1073408</pub-id></nlm-citation></ref><ref id="B19" content-type="book"><label>19</label><nlm-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lavalle</surname><given-names>S. M.</given-names></name></person-group><source><italic>Planning Algorithms</italic></source><year>2006</year><publisher-loc>Cambridge, Mass, USA</publisher-loc><publisher-name>Cambridge University Press</publisher-name></nlm-citation></ref><ref id="B20" content-type="article"><label>20</label><nlm-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Li</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name></person-group><article-title>A hierarchical model incorporating segmented regions and pixel descriptors for video background subtraction</article-title><source><italic>IEEE Transactions on Industrial Informatics</italic></source><year>2012</year><volume>8</volume><issue>1</issue><fpage>118</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1109/TII.2011.2173202</pub-id></nlm-citation></ref><ref id="B21" content-type="inproceedings"><label>21</label><nlm-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Da Silva</surname><given-names>A. R.</given-names></name><name><surname>Lages</surname><given-names>W. S.</given-names></name><name><surname>Chaimowicz</surname><given-names>L.</given-names></name></person-group><article-title>Improving boids algorithm in GPU using estimated self occlusion</article-title><conf-name>Proceedings of SBGames'08: Computing Track, Computers in Entertainment (CIE)</conf-name><conf-date>2008</conf-date><fpage>41</fpage><lpage>46</lpage></nlm-citation></ref></ref-list></back></article>